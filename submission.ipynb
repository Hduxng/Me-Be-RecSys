{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13974139,"sourceType":"datasetVersion","datasetId":8908991},{"sourceId":14161761,"sourceType":"datasetVersion","datasetId":9026512},{"sourceId":14247594,"sourceType":"datasetVersion","datasetId":9090289},{"sourceId":14251086,"sourceType":"datasetVersion","datasetId":9092789},{"sourceId":14258010,"sourceType":"datasetVersion","datasetId":9097810}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install deepctr-torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T15:05:14.723043Z","iopub.execute_input":"2025-12-22T15:05:14.723292Z","iopub.status.idle":"2025-12-22T15:05:19.657387Z","shell.execute_reply.started":"2025-12-22T15:05:14.723260Z","shell.execute_reply":"2025-12-22T15:05:19.656509Z"}},"outputs":[{"name":"stdout","text":"Collecting deepctr-torch\n  Downloading deepctr_torch-0.2.9-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from deepctr-torch) (2.8.0+cu126)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from deepctr-torch) (4.67.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from deepctr-torch) (1.6.1)\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from deepctr-torch) (2.19.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deepctr-torch) (3.4.0)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->deepctr-torch) (2.0.2)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->deepctr-torch) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->deepctr-torch) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->deepctr-torch) (3.6.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (25.9.23)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (5.29.5)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (2.32.5)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (3.1.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (2.0.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (1.75.1)\nRequirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (2.19.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (3.10.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (3.15.1)\nRequirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->deepctr-torch) (0.5.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->deepctr-torch) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch) (0.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (2025.11.12)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.2.0->deepctr-torch) (1.3.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->deepctr-torch) (3.9)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->deepctr-torch) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->deepctr-torch) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.2.0->deepctr-torch) (3.0.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->deepctr-torch) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->deepctr-torch) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->deepctr-torch) (0.1.2)\nDownloading deepctr_torch-0.2.9-py3-none-any.whl (82 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: deepctr-torch\nSuccessfully installed deepctr-torch-0.2.9\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport gc\nimport json\nimport pickle\nimport glob\nimport pandas as pd\nimport numpy as np\nimport polars as pl\nimport lightgbm as lgb\nfrom datetime import date\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nimport torch\nfrom deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\nfrom deepctr_torch.models import DeepFM\n\n# ==================== 1. C·∫§U H√åNH PATH ====================\nDATA_DIR = \"/kaggle/input/recsys-data\"\nRAW_DATA_DIR = \"/kaggle/input/sales-dataset\"\n\n# T·ª∞ ƒê·ªòNG CH·ªåN GT: ∆Øu ti√™n Final Test n·∫øu c√≥\nGT_PATH_FINAL = \"/kaggle/input/final-test/final_groundtruth.pkl\"\nGT_PATH_OLD = \"/kaggle/input/sales-test/groundtruth.pkl\"\nGT_PATH = GT_PATH_FINAL if os.path.exists(GT_PATH_FINAL) else GT_PATH_OLD\n\nLGBM_MODEL_PATH = f\"{DATA_DIR}/lightgbm_model.txt\"\nTRAIN_PATH = f\"{DATA_DIR}/train_data.parquet\"\nVAL_PATH = f\"{DATA_DIR}/val_data.parquet\"\nINF_PATH = f\"{DATA_DIR}/inf_data.parquet\"\n\n# T·ª∑ tr·ªçng Ensemble\nW_LGBM = 0.6\nW_DEEP = 0.4\n\nprint(f\">>> USING GROUND TRUTH AT: {GT_PATH}\")\n\n# ==================== 2. H√ÄM H·ªñ TR·ª¢ (ADVANCED COLD START) ====================\ndef load_data_cold_start():\n    print(f\">>> Loading raw data for Cold Start from: {RAW_DATA_DIR}...\")\n    try:\n        purchase_path = f\"{RAW_DATA_DIR}/sales_pers.purchase_history_daily_chunk_*.parquet\"\n        user_path = f\"{RAW_DATA_DIR}/sales_pers.user_chunk_*.parquet\"\n        \n        if not glob.glob(purchase_path):\n            print(f\"‚ö†Ô∏è Warning: Kh√¥ng t√¨m th·∫•y file t·∫°i {purchase_path}.\")\n            return None, None\n\n        lz_trans = (\n            pl.scan_parquet(purchase_path)\n            .filter((pl.col(\"is_deleted\") == False) & (pl.col(\"quantity\") > 0))\n            .select([\n                pl.col(\"customer_id\").cast(pl.Int32), \n                pl.col(\"item_id\").cast(pl.String), \n                pl.col(\"date_key\").cast(pl.String).str.strptime(pl.Date, \"%Y%m%d\").alias(\"date\")\n            ])\n        )\n        lz_users = pl.scan_parquet(user_path).filter(pl.col(\"is_deleted\") == False).select([\n            pl.col(\"customer_id\").cast(pl.Int32), \n            pl.col(\"province\").fill_null(\"Unknown\").cast(pl.String)\n        ])\n        return lz_trans, lz_users\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Warning: Cold start load failed ({e}).\")\n        return None, None\n\ndef fill_cold_start_advanced(pred_recs, target_ids, lz_trans, lz_users):\n    if lz_trans is None or lz_users is None: return pred_recs\n    \n    print(f\">>> [Advanced] Filling Cold Start for {len(target_ids)} users...\")\n    \n    safe_target_ids_int = []\n    for uid in target_ids:\n        try: safe_target_ids_int.append(int(uid))\n        except: continue\n\n    # 1. Repurchase History\n    print(\"   -> Computing User Purchase History...\")\n    user_history = (\n        lz_trans.filter(pl.col(\"customer_id\").is_in(safe_target_ids_int))\n        .group_by([\"customer_id\", \"item_id\"])\n        .len()\n        .sort([\"customer_id\", \"len\"], descending=True)\n        .group_by(\"customer_id\")\n        .head(20)\n        .group_by(\"customer_id\")\n        .agg(pl.col(\"item_id\"))\n        .collect()\n    )\n    hist_dict = dict(zip(user_history[\"customer_id\"].to_list(), user_history[\"item_id\"].to_list()))\n    \n    # 2. Top Global\n    top_global = lz_trans.filter(pl.col(\"date\") >= date(2024, 12, 1)).group_by(\"item_id\").len().sort(\"len\", descending=True).limit(20).select(\"item_id\").collect().to_series().to_list()\n    \n    # 3. Top Province\n    user_prov = lz_users.filter(pl.col(\"customer_id\").is_in(safe_target_ids_int)).collect()\n    u_prov_map = dict(zip(user_prov[\"customer_id\"].to_list(), user_prov[\"province\"].to_list()))\n    \n    top_prov = (\n        lz_trans.filter(pl.col(\"date\") >= date(2024, 11, 1))\n        .join(lz_users, on=\"customer_id\")\n        .group_by([\"province\", \"item_id\"]).len()\n        .sort([\"province\", \"len\"], descending=True)\n        .group_by(\"province\").head(10)\n        .group_by(\"province\").agg(pl.col(\"item_id\"))\n        .collect()\n    )\n    prov_dict = dict(zip(top_prov[\"province\"].to_list(), top_prov[\"item_id\"].to_list()))\n\n    # 4. Filling Logic\n    final_preds = pred_recs.copy()\n    \n    for u in target_ids:\n        u_str = str(u)\n        current_items = final_preds.get(u_str, [])\n        \n        # Priority: Repurchase -> Province -> Global\n        if len(current_items) < 10:\n            u_int = int(u) if str(u).isdigit() else -1\n            \n            # Repurchase\n            for item in hist_dict.get(u_int, []):\n                if item not in current_items: current_items.append(item)\n                if len(current_items) >= 10: break\n            \n            # Province\n            if len(current_items) < 10:\n                prov = u_prov_map.get(u_int, \"Unknown\")\n                for item in prov_dict.get(prov, []):\n                    if item not in current_items: current_items.append(item)\n                    if len(current_items) >= 10: break\n            \n            # Global\n            if len(current_items) < 10:\n                for item in top_global:\n                    if item not in current_items: current_items.append(item)\n                    if len(current_items) >= 10: break\n        \n        final_preds[u_str] = current_items[:10]\n            \n    return final_preds\n\n# --- H√ÄM EVALUATE M·ªöI: H·ªñ TR·ª¢ C·∫¢ DICT V√Ä DATAFRAME ---\ndef evaluate_robust(pred, gt_path, model_users_set):\n    \"\"\"\n    T√≠nh Precision@10 v√† chia t√°ch k·∫øt qu·∫£ th√†nh 2 nh√≥m (Warm/Cold).\n    H·ªó tr·ª£ ƒë·ªçc c·∫£ file Dictionary (c≈©) v√† DataFrame (m·ªõi).\n    \"\"\"\n    if not os.path.exists(gt_path): \n        print(f\"‚ö†Ô∏è GT Path not found.\")\n        return\n        \n    print(f\">>> Calculating Precision by Groups (Robust Mode)...\")\n    with open(gt_path, 'rb') as f: \n        gt_data = pickle.load(f)\n    \n    # X·ª≠ l√Ω ƒë·ªãnh d·∫°ng d·ªØ li·ªáu\n    gt_dict = {}\n    if isinstance(gt_data, dict):\n        gt_dict = {str(k): v for k, v in gt_data.items()}\n    elif isinstance(gt_data, pd.DataFrame):\n        print(\"   -> Detected DataFrame Ground Truth. Converting...\")\n        # Gi·∫£ ƒë·ªãnh c·ªôt 0 l√† User, c·ªôt 1 l√† List Items\n        user_col = gt_data.columns[0]\n        item_col = gt_data.columns[1]\n        gt_dict = gt_data.set_index(user_col)[item_col].to_dict()\n        gt_dict = {str(k): v for k, v in gt_dict.items()}\n    \n    warm_precs = []\n    cold_precs = []\n    \n    for u, true_items in gt_dict.items():\n        if u in pred:\n            rec_items = pred[u][:10]\n            try:\n                t_set = set(str(x) for x in true_items) if isinstance(true_items, (np.ndarray, list)) else set()\n                r_set = set(str(x) for x in rec_items)\n                hits = len(t_set & r_set)\n                precision = hits / 10.0\n                \n                # Ph√¢n lo·∫°i User\n                if u in model_users_set:\n                    warm_precs.append(precision)\n                else:\n                    cold_precs.append(precision)\n            except: continue\n            \n    # T√≠nh Mean\n    warm_score = np.mean(warm_precs) if warm_precs else 0.0\n    cold_score = np.mean(cold_precs) if cold_precs else 0.0\n    total_score = np.mean(warm_precs + cold_precs) if (warm_precs + cold_precs) else 0.0\n    \n    print(\"-\" * 50)\n    print(f\"üìä REPORT FOR {len(gt_dict)} USERS:\")\n    print(f\"   1. Warm Users (Model Predict):  {len(warm_precs)} users | Precision: {warm_score:.4f}\")\n    print(f\"   2. Cold Users (Fill Strategy):  {len(cold_precs)} users | Precision: {cold_score:.4f}\")\n    print(f\"   --------------------------------------------------\")\n    print(f\"   üèÜ OVERALL PRECISION@10:        {total_score:.4f}\")\n    print(\"-\" * 50)\n\n# ==================== 3. CHU·∫®N B·ªä D·ªÆ LI·ªÜU ====================\nprint(\">>> [DeepFM] LOADING DATA...\")\ntrain_df = pd.read_parquet(TRAIN_PATH)\ninf_df = pd.read_parquet(INF_PATH)\n\nif os.path.exists(VAL_PATH):\n    print(\"   -> Merging Val into Train...\")\n    val_df = pd.read_parquet(VAL_PATH)\n    train_df = pd.concat([train_df, val_df], axis=0, ignore_index=True)\n    del val_df\n\ntrain_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n\nsparse_features = ['customer_id', 'item_id', 'brand', 'category_l1', \n                   'cat_l1_lower', 'age_group', 'segment_value', 'segment_variety']\ndense_features = ['price', 'avg_order_value', 'unique_cats', 'baby_age_months', \n                  'item_popularity', 'days_since_last_purchase', 'user_brand_buy_count']\n\nfor col in dense_features:\n    if col not in train_df.columns: train_df[col] = 0\n    if col not in inf_df.columns: inf_df[col] = 0\n\ntrain_deep = train_df.copy()\ninf_deep = inf_df.copy()\n\nfor df in [train_deep, inf_deep]:\n    df[sparse_features] = df[sparse_features].fillna('-1').astype(str)\n    df[dense_features] = df[dense_features].fillna(0)\n\nprint(\"   -> Encoding & Scaling...\")\nitem_encoder = LabelEncoder()\nall_items = pd.concat([train_deep['item_id'], inf_deep['item_id']]).unique()\nitem_encoder.fit(all_items)\n\nfor feat in sparse_features:\n    lbe = LabelEncoder()\n    if feat == 'item_id': lbe = item_encoder\n    else: lbe.fit(pd.concat([train_deep[feat], inf_deep[feat]]).unique())\n    train_deep[feat] = lbe.transform(train_deep[feat])\n    inf_deep[feat] = lbe.transform(inf_deep[feat])\n\nmms = MinMaxScaler(feature_range=(0, 1))\nmms.fit(pd.concat([train_deep[dense_features], inf_deep[dense_features]]))\ntrain_deep[dense_features] = mms.transform(train_deep[dense_features])\ninf_deep[dense_features] = mms.transform(inf_deep[dense_features])\n\n# ==================== 4. TRAIN DEEPFM ====================\nprint(\">>> [DeepFM] TRAINING...\")\nfixlen_feature_columns = [\n    SparseFeat(feat, vocabulary_size=pd.concat([train_deep[feat], inf_deep[feat]]).max() + 1, embedding_dim=16)\n    for feat in sparse_features\n] + [DenseFeat(feat, 1) for feat in dense_features]\n\ndnn_feature_columns = fixlen_feature_columns\nlinear_feature_columns = fixlen_feature_columns\nfeature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n\ntrain_model_input = {name: train_deep[name] for name in feature_names}\ninf_model_input = {name: inf_deep[name] for name in feature_names}\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nmodel = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary',\n               dnn_hidden_units=(256, 128, 64), l2_reg_embedding=1e-5, device=device)\n\nmodel.compile(\"adam\", \"binary_crossentropy\", metrics=['auc'])\nmodel.fit(train_model_input, train_deep['label'].values, batch_size=1024, epochs=3, verbose=1, validation_split=0.1)\n\ndeepfm_scores = model.predict(inf_model_input, batch_size=2048).flatten()\nprint(\"   -> DeepFM Prediction Done.\")\n\ndel train_deep, inf_deep, model, train_model_input, inf_model_input, train_df\ngc.collect()\n\n# ==================== 5. LIGHTGBM ====================\nprint(\">>> [LightGBM] PREDICTING...\")\nlgbm_scores = deepfm_scores\nlgbm_success = False\n\nif os.path.exists(LGBM_MODEL_PATH):\n    try:\n        print(\"   -> Loading Inf Data via Polars...\")\n        df_inf_lgbm = pl.read_parquet(INF_PATH).to_pandas()\n        cat_feats = [\"brand\", \"category_l1\", \"age_group\", \"segment_value\", \"segment_variety\"]\n        ignore_cols = [\"customer_id\", \"item_id\", \"label\", \"last_buy_date\", \"date\", \"cat_l1_lower\", \"score\", \"temp_score\"]\n        \n        for c in cat_feats:\n            if c in df_inf_lgbm.columns: df_inf_lgbm[c] = df_inf_lgbm[c].astype('category')\n\n        features = [c for c in df_inf_lgbm.columns if c not in ignore_cols]\n        bst = lgb.Booster(model_file=LGBM_MODEL_PATH)\n        lgbm_scores = bst.predict(df_inf_lgbm[features])\n        \n        print(\"   -> LightGBM Prediction Done.\")\n        lgbm_success = True\n        del df_inf_lgbm\n    except Exception as e:\n        print(f\"‚ö†Ô∏è ERROR LightGBM: {e}\")\n        W_LGBM = 0.0\n        W_DEEP = 1.0\n    gc.collect()\n\n# ==================== 6. ENSEMBLE & RANKING ====================\nprint(f\">>> ENSEMBLING: {W_LGBM}*LGBM + {W_DEEP}*DeepFM\")\ninf_df_final = pd.read_parquet(INF_PATH, columns=['customer_id', 'item_id'])\n\nif lgbm_success:\n    inf_df_final['final_score'] = (W_LGBM * lgbm_scores) + (W_DEEP * deepfm_scores)\nelse:\n    inf_df_final['final_score'] = deepfm_scores\n\nprint(\">>> RANKING...\")\ninf_df_final = inf_df_final.sort_values(['customer_id', 'final_score'], ascending=[True, False])\ntop_k_df = inf_df_final.groupby('customer_id').head(10)\n\n# L∆∞u danh s√°ch user m√† Model ƒë√£ d·ª± ƒëo√°n ƒë∆∞·ª£c (Warm Users)\ntop_k_df = top_k_df.copy()\ntop_k_df['customer_id'] = top_k_df['customer_id'].astype(str)\ngrouped = top_k_df.groupby('customer_id')['item_id'].apply(list).to_dict()\n\n# SET quan tr·ªçng: D√πng ƒë·ªÉ ph√¢n bi·ªát Warm vs Cold User\nMODEL_USERS_SET = set(grouped.keys())\n\nfinal_submission = grouped\n\n# ==================== 7. SUBMIT & ROBUST EVALUATION ====================\nprint(\"\\n>>> üèÅ FINALIZING SUBMISSION...\")\n\n# Load Cold Start Data\nlz_trans, lz_users = load_data_cold_start()\n\n# X√°c ƒë·ªãnh Target IDs t·ª´ file GroundTruth chu·∫©n\ntarget_ids = []\nif os.path.exists(GT_PATH):\n    print(f\"   -> Loading Target IDs from GT: {GT_PATH}\")\n    with open(GT_PATH, 'rb') as f: \n        gt_data = pickle.load(f)\n    \n    if isinstance(gt_data, dict):\n        target_ids = list(gt_data.keys())\n    elif isinstance(gt_data, pd.DataFrame):\n        # L·∫•y c·ªôt ƒë·∫ßu ti√™n l√†m ID\n        target_ids = gt_data.iloc[:, 0].astype(str).tolist()\nelse:\n    print(\"‚ö†Ô∏è No GT found. Using IDs from submission.\")\n    target_ids = list(final_submission.keys())\n\n# ƒêi·ªÅn khuy·∫øt (Fill Cold Start)\nfinal_submission = fill_cold_start_advanced(final_submission, target_ids, lz_trans, lz_users)\n\n# ƒê√ÅNH GI√Å\nif os.path.exists(GT_PATH):\n    evaluate_robust(final_submission, GT_PATH, MODEL_USERS_SET)\n\n# Save\nwith open(\"submission_final.json\", 'w', encoding='utf-8') as f:\n    json.dump(final_submission, f, ensure_ascii=False, indent=4)\nprint(\"\\n‚úÖ Saved results to submission_final.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T15:41:10.056896Z","iopub.execute_input":"2025-12-22T15:41:10.057208Z","iopub.status.idle":"2025-12-22T15:49:58.248210Z","shell.execute_reply.started":"2025-12-22T15:41:10.057181Z","shell.execute_reply":"2025-12-22T15:49:58.247439Z"}},"outputs":[{"name":"stdout","text":">>> USING GROUND TRUTH AT: /kaggle/input/final-test/final_groundtruth.pkl\n>>> [DeepFM] LOADING DATA...\n   -> Merging Val into Train...\n   -> Encoding & Scaling...\n>>> [DeepFM] TRAINING...\ncuda:0\nTrain on 3213837 samples, validate on 357094 samples, 3139 steps per epoch\n","output_type":"stream"},{"name":"stderr","text":"3139it [00:58, 53.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n60s - loss:  0.4484 - auc:  0.8645 - val_auc:  0.8775\n","output_type":"stream"},{"name":"stderr","text":"3139it [00:58, 53.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/3\n60s - loss:  0.3775 - auc:  0.9076 - val_auc:  0.8703\n","output_type":"stream"},{"name":"stderr","text":"3139it [00:58, 53.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/3\n61s - loss:  0.2919 - auc:  0.9460 - val_auc:  0.8529\n   -> DeepFM Prediction Done.\n>>> [LightGBM] PREDICTING...\n   -> Loading Inf Data via Polars...\n   -> LightGBM Prediction Done.\n>>> ENSEMBLING: 0.6*LGBM + 0.4*DeepFM\n>>> RANKING...\n\n>>> üèÅ FINALIZING SUBMISSION...\n>>> Loading raw data for Cold Start from: /kaggle/input/sales-dataset...\n   -> Loading Target IDs from GT: /kaggle/input/final-test/final_groundtruth.pkl\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/1619246147.py:334: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n  gt_data = pickle.load(f)\n","output_type":"stream"},{"name":"stdout","text":">>> [Advanced] Filling Cold Start for 644970 users...\n   -> Computing User Purchase History...\n>>> Calculating Precision by Groups (Robust Mode)...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/1619246147.py:153: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n  gt_data = pickle.load(f)\n","output_type":"stream"},{"name":"stdout","text":"   -> Detected DataFrame Ground Truth. Converting...\n--------------------------------------------------\nüìä REPORT FOR 644970 USERS:\n   1. Warm Users (Model Predict):  225552 users | Precision: 0.1323\n   2. Cold Users (Fill Strategy):  419418 users | Precision: 0.0379\n   --------------------------------------------------\n   üèÜ OVERALL PRECISION@10:        0.0709\n--------------------------------------------------\n\n‚úÖ Saved results to submission_final.json\n","output_type":"stream"}],"execution_count":6}]}